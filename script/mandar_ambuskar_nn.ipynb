{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fbf3f41d",
   "metadata": {},
   "source": [
    "### Importing all the important libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b38cb9b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\scipy\\__init__.py:155: UserWarning: A NumPy version >=1.18.5 and <1.25.0 is required for this version of SciPy (detected version 1.26.3\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\MANDAR\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pathlib\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import PIL\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, BatchNormalization, Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from glob import glob\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "25bcd806",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the path for train and test images\n",
    "data_dir_train = pathlib.Path(r\"C:\\Users\\MANDAR\\Downloads\\upgrade\\NN\\Project\\Skin cancer ISIC The International Skin Imaging Collaboration\\Train\")\n",
    "data_dir_test = pathlib.Path(r\"C:\\Users\\MANDAR\\Downloads\\upgrade\\NN\\Project\\Skin cancer ISIC The International Skin Imaging Collaboration\\Test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "896da1be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2239\n",
      "118\n"
     ]
    }
   ],
   "source": [
    "image_count_train = len(list(data_dir_train.glob('*/*.jpg')))\n",
    "print(image_count_train)\n",
    "image_count_test = len(list(data_dir_test.glob('*/*.jpg')))\n",
    "print(image_count_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2f4a272",
   "metadata": {},
   "source": [
    "### Create a dataset\n",
    "\n",
    "Define some parameters for the loader:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9745bc0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "img_height = 180\n",
    "img_width = 180"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62ac7236",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    data_dir_train,\n",
    "    validation_split= 0.4,  # You can adjust the validation split as needed\n",
    "    subset=\"training\",\n",
    "    seed=123,\n",
    "    image_size=(img_height, img_width),\n",
    "    batch_size= batch_size  # You can adjust the batch size as needed\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b44ac34",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_ds =  tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    data_dir_test,\n",
    "    validation_split=0.4,  # You can adjust the validation split as needed\n",
    "    subset=\"validation\",\n",
    "    seed=123,\n",
    "    image_size=(img_height, img_width),\n",
    "    batch_size= batch_size  # You can adjust the batch size as needed\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7ff6572",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = train_ds.class_names\n",
    "print(class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a07fb7e",
   "metadata": {},
   "source": [
    "### Visualize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad87182a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def display_images_in_grid(images, grid_size=(1, 4)):\n",
    "    fig, axs = plt.subplots(*grid_size, figsize=(15, 7))\n",
    "    axs = axs.ravel()\n",
    "\n",
    "    for i, img in enumerate(images):\n",
    "        axs[i].imshow(img)\n",
    "        axs[i].axis('off')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "def print_images_from_folders(root_dir, num_images=4):\n",
    "    for foldername in os.listdir(root_dir):\n",
    "        folder_path = os.path.join(root_dir, foldername)\n",
    "\n",
    "        # Check if the current item is a directory\n",
    "        if os.path.isdir(folder_path):\n",
    "            print(f\"Images from folder: {foldername}\")\n",
    "            image_count = 0\n",
    "            images_to_display = []\n",
    "\n",
    "            # Loop through files in the folder\n",
    "            for filename in os.listdir(folder_path):\n",
    "                if image_count == num_images:\n",
    "                    break\n",
    "\n",
    "                file_path = os.path.join(folder_path, filename)\n",
    "\n",
    "                # Check if the current item is a file and is an image (you can customize the list of valid extensions)\n",
    "                if os.path.isfile(file_path) and any(file_path.lower().endswith(ext) for ext in ['.jpg', '.jpeg', '.png']):\n",
    "                    # Open the image and append it to the list\n",
    "                    img = Image.open(file_path)\n",
    "                    images_to_display.append(img)\n",
    "                    image_count += 1\n",
    "\n",
    "            # Display the images in a grid\n",
    "            display_images_in_grid(images_to_display)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print_images_from_folders(data_dir_train)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f46484e",
   "metadata": {},
   "outputs": [],
   "source": [
    "UTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "train_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)\n",
    "val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04bb9550",
   "metadata": {},
   "source": [
    "### Create the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8487f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the seed for reproducibility\n",
    "seed = 123\n",
    "tf.random.set_seed(seed)\n",
    "\n",
    "# Define the image size\n",
    "img_height, img_width = 180, 180\n",
    "num_classes = 9\n",
    "\n",
    "# Define the CNN model\n",
    "model = models.Sequential()\n",
    "\n",
    "# Preprocessing layer to rescale pixel values between (0, 1)\n",
    "model.add(layers.experimental.preprocessing.Rescaling(1./255, input_shape=(img_height, img_width, 3)))\n",
    "\n",
    "# Convolutional and pooling layers\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(img_height, img_width, 3)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "# Flatten layer to transition from convolutional layers to dense layers\n",
    "model.add(layers.Flatten())\n",
    "\n",
    "# Dense layers\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512,kernel_regularizer=l2(0.01)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7855d2b9",
   "metadata": {},
   "source": [
    "### Compile the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7175d97d",
   "metadata": {},
   "outputs": [],
   "source": [
    "your_loss_function_goes_here = 'sparse_categorical_crossentropy'\n",
    "\n",
    "model.compile(optimizer=\"adam\",\n",
    "              loss=your_loss_function_goes_here,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb7c7627",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62ef8be6",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 20\n",
    "history = model.fit(train_ds,\n",
    "                    validation_data=val_ds,\n",
    "                    epochs=epochs,\n",
    "                    batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b76acc4",
   "metadata": {},
   "source": [
    "### Visualizing training results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaf5d3f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs_range = range(epochs)\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_range, loss, label='Training Loss')\n",
    "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51fcf6eb",
   "metadata": {},
   "source": [
    "### Create the model, compile and train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f5e8525",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the seed for reproducibility\n",
    "seed = 123\n",
    "tf.random.set_seed(seed)\n",
    "\n",
    "# Define the image size\n",
    "img_height, img_width = 180, 180\n",
    "num_classes = 9\n",
    "\n",
    "# Define the CNN model\n",
    "model = models.Sequential()\n",
    "\n",
    "# Preprocessing layer to rescale pixel values between (0, 1)\n",
    "model.add(layers.experimental.preprocessing.Rescaling(1./255, input_shape=(img_height, img_width, 3)))\n",
    "\n",
    "# Convolutional and pooling layers\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(img_height, img_width, 3)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "# Flatten layer to transition from convolutional layers to dense layers\n",
    "model.add(layers.Flatten())\n",
    "\n",
    "# Dense layers\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512,kernel_regularizer=l2(0.01)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ef54ff1",
   "metadata": {},
   "source": [
    "### Compiling the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfd75b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "your_loss_function_goes_here = 'sparse_categorical_crossentropy'\n",
    "\n",
    "model.compile(optimizer=\"adam\",\n",
    "              loss=your_loss_function_goes_here,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c087bf3",
   "metadata": {},
   "source": [
    "### Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8abc6fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "  train_ds,\n",
    "  validation_data=val_ds,\n",
    "  epochs=epochs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4798f291",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs_range = range(epochs)\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_range, loss, label='Training Loss')\n",
    "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
